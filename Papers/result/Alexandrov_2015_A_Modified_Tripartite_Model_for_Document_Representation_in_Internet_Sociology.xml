<article><preamble>Alexandrov 2015 A Modified Tripartite Model for Document Representation in Internet Sociology</preamble><titre>A Modified Tripartite Model for Document</titre><auteur>Representation in Internet Sociology
Mikhail Alexandrov1,2 , Vera Danilova1,2(B) , and Xavier Blanco1
1

2

Autonomous University of Barcelona, Barcelona, Spain
{MAlexandrov.UAB,XblancoE}@gmail.com
Russian Presidential Academy of National Economy and Public Administration,
Moscow, Russian Federation
vera.danilova@e-campus.uab.cat

</auteur><abstract>. Seven years ago Peter Mika (Yahoo! Research) proposed atripartite model of actors, concepts and instances for document representation in the study of social networks. We propose a modified model,where instead of document authors we consider textual mentions of persons and institutions as actors. This representation proves to be moreappropriate for the solution of a range of Internet Sociology tasks. In thepaper we describe experiments with the modified model and provide somebackground on the tools that can be used to build it. The model is testedon the experimental corpora of Russian news (educational domain). Theresearch reflects the pilot study findings.</abstract><introduction>
The automatic detection of document and corpus topic is one of the most popular tasks within the natural language processing. The traditional model, where
each document is represented by a vector describing the distribution of keywords
in a document or corpus, works quite well. On the basis of this representation,
it becomes possible to group similar documents and reveal the corpus structure,
as well as to group keywords and build topic vocabularies [6,11]. Considering
each document as an ontology instance and a set of keywords as a concept, we
obtain a two-layer ontology model. The appearance of social networks allowed
the researchers to bring in the social aspect, thus creating a tripartite model
of ontology for Social Networks Analysis containing document authors (actors),
document content (instances), and tags (concepts) [13]. Three-layer model is
a tool for studying the emergence and dynamics of communities on the basis
of user-generated content. Author pro&#64257;ling gave an opportunity to analyze the
Under partial support of the Catholic University of San Pablo (grant FINCyTPERU).
c Springer International Publishing Switzerland 2015

Q. Chen et al. (Eds.): DEXA 2015, Part II, LNCS 9262, pp. 323&#8211;330, 2015.
DOI: 10.1007/978-3-319-22852-5 27

324

M. Alexandrov et al.

attitude of di&#64256;erent user categories towards particular events and topics. However, it is not only the author&#8217;s personality that matters for solving Internet
Sociology tasks, but also the awareness of the connection between the text mentions of personalities and organizations and concepts and instances within text.
This knowledge is important, when dealing with traditional mass media - epublications created by analysts and journalists. In this case, the Actor in the
Actor-Concept-Instance triple is a Named Entity (NE) mention (person and
organization names), the Concept is an automatically generated topic description, not user-generated tags, and the Instance is a set of phrases with a high level
of speci&#64257;city that frequently denote events (olympiad, demonstration, etc.). The
present paper considers the use of this modi&#64257;ed tripartite model of ontologies
for the purposes of Internet Sociology studies.
The rest of the article is organized as follows. Section 2 provides a description of the three-layer model. Section 3 presents the experiments on real-world
data that include model construction, opinion mining and clustering. Section 4
concludes the paper. This paper outlines our pilot-study experiments performed
on the basis of Russian newspaper articles. The listed examples are translated
into English.

</introduction><corps>The automatic detection of document and corpus topic is one of the most popular tasks within the natural language processing. The traditional model, whereeach document is represented by a vector describing the distribution of keywordsin a document or corpus, works quite well. On the basis of this representation,it becomes possible to group similar documents and reveal the corpus structure,as well as to group keywords and build topic vocabularies [6,11]. Consideringeach document as an ontology instance and a set of keywords as a concept, weobtain a two-layer ontology model. The appearance of social networks allowedthe researchers to bring in the social aspect, thus creating a tripartite modelof ontology for Social Networks Analysis containing document authors (actors),document content (instances), and tags (concepts) [13]. Three-layer model isa tool for studying the emergence and dynamics of communities on the basisof user-generated content. Author pro&#64257;ling gave an opportunity to analyze theUnder partial support of the Catholic University of San Pablo (grant FINCyTPERU).c Springer International Publishing Switzerland 2015Q. Chen et al. (Eds.): DEXA 2015, Part II, LNCS 9262, pp. 323&#8211;330, 2015.DOI: 10.1007/978-3-319-22852-5 27324M. Alexandrov et al.attitude of di&#64256;erent user categories towards particular events and topics. However, it is not only the author&#8217;s personality that matters for solving InternetSociology tasks, but also the awareness of the connection between the text mentions of personalities and organizations and concepts and instances within text.This knowledge is important, when dealing with traditional mass media - epublications created by analysts and journalists. In this case, the Actor in theActor-Concept-Instance triple is a Named Entity (NE) mention (person andorganization names), the Concept is an automatically generated topic description, not user-generated tags, and the Instance is a set of phrases with a high levelof speci&#64257;city that frequently denote events (olympiad, demonstration, etc.). Thepresent paper considers the use of this modi&#64257;ed tripartite model of ontologiesfor the purposes of Internet Sociology studies.The rest of the article is organized as follows. Section 2 provides a description of the three-layer model. Section 3 presents the experiments on real-worlddata that include model construction, opinion mining and clustering. Section 4concludes the paper. This paper outlines our pilot-study experiments performedon the basis of Russian newspaper articles. The listed examples are translatedinto English.2Multipartite Models2.1Tripartite ModelThe tripartite model uses three layers of descriptors (keywords) for documentrepresentation as follows. The &#64257;rst layer is formed from a list of actors or personand organization names that are mentioned in a document; the second layer isa list of concepts that characterize the domain a given document belongs to;the third layer is represented by the instances or document-speci&#64257;c collocations.Each element of each list contains a set of tokens, which number varies from 1 to5. As for a single document, the tripartite model can be created for a corpus ofdocuments. The corpus representation is a list of actors, concepts and instancesthat are mentioned throughout a corpus. Table 1 presents an excerpt from amodel for a corpus of 250 documents related to the educational domain.Here, the NE &#8220;Dr. Livanov&#8221; is a mention of the Russian Minister of Educationand Science. &#8220;Dr. Rukshin&#8221; is one of the leading Russian school teachers. Parliament means a discussion at the State Duma. President means here a discussionat the Public Council under the President&#8217;s administration. Moscow means theDepartment of Education of the Moscow Regional Government. It should beTable 1. An excerpt from our experimental corpus model (educational domain)No.ActorConceptInstance1Ministry of EducationYoung TalentLaw of Education, Parliament, Mar. 20132Cabinet of MinistersPrimary SchoolLaw of Education, President, Jul. 20143Higher School of EconomicsSecondary SchoolCollege Education, Parliament, Dec. 2013A Modified Tripartite Model for Document Representation325noted that the frequency of occurrence of key terms in a document is not takeninto account when building the model. We focus on the presence or absence ina document of the keywords from the corpus-based model.2.2Bipartite ModelThe notation for the dimensionality of each layer (list) for the corpus of documents is as follows. Let Ka be the number of actors, Ki - the number of instances,and Kc - the number of concepts.Actors-Concepts model (AC model) shows what keywords each person ororganization is connected with in a text. It can be presented as a table (matrix)of size M (Ka , Kc ). Matrix transposition MT of size (Kc , Ka ) will show the actorsthat are related to a given concept (CA model).The connection between an actor and a concept can be evaluated using theJaccard distance [6]:J(Ai , Cj ) = 2 &#215;|DAi &#8745; DCj |,|DAi &#8746; DCj |(1)where Ai and Cj represent a speci&#64257;c actor and a concept respectively, DAiand DCj correspond to the collections of documents, where the mentioned concept and actor occur. The number of documents, where the given concept andactor co-occur, in the numerator is doubled in order to normalize the connectiondegree from [0.0, 1.0].A weight WA for each actor on the concepts layer, and a weight WC for eachKcjconcept on the actors layer can be introduced as follows: WA = i=1J(Ai , Cj )(Kcj is the number of concepts related to a speci&#64257;c actor, and J(Ai , Cj ) is theJaccard distance between the selected actor and one of the related concepts) andKajWC = i=1J(Ci , Aj ) (Kaj is the number of actors related to a speci&#64257;c concept,and J(Ci , Aj ) is the Jaccard distance between the selected concept and one ofthe related actors).Concepts-Instances model (CI model) shows the speci&#64257;c collocations eachconcept (keyword set) is related to and vice versa. The weights are introducedin the same way as for the previous models. CI and IC models are commonlyused for natural language processing purposes in two-layer model-based document parametrization: CI matrix shows the distribution of keywords throughoutthe documents, and IC - speci&#64257;c expressions that are &#8220;spotted&#8221; in each of thedocuments.The Instances-Actors (IA) and Actors-Instances (AI) models can bebuilt by transforming the previously obtained matrices: (AI) = (AC) &#215; (CI)and (IA) = (IC) &#215; (CA).2.3Unipartite ModelTwo-layer models can be reduced to single-layer models, which further allowsto perform automatic grouping. A one-layer model uses only one of the layers326M. Alexandrov et al.or dimensions (actors, concepts or instances) for document and corpus representation. In order to properly build the unipartite model, let us &#64257;rst considerthe (AC) model, where we can &#64257;nd the connections between two actors on theconcept layer. To this end, the calculation of the number of shared concepts foreach pair of actors should be performed. If all of the concepts are the same, theconnection will have its maximum weight, and if no concepts are shared, theconnection is insigni&#64257;cant. The connection can be evaluated using the Jaccarddistance as follows:J(Ai , Aj ) = 2 &#215;|Kci &#8745; Kcj |,|Kci &#8746; Kcj |(2)where Ai and Aj are the corresponding actors, Kci and Kcj are sets of concepts related to the actors Ai and Aj correspondingly. The number of sharedconcepts in the numerator is doubled in order to normalize the connection degreefrom [0.0, 1.0].Having performed a pairwise evaluation of actors connection on the concepts layer, we can build a matrix Actors - Actors (AA), which is the targetunipartite model. The resulting proximity matrix is the input for the clusteranalysis. As a result, we obtain the groups of interconnected actors. It is ameaningful result: each cluster contains person and organization names discussedwithin the same topics. In a similar way, the reversed (CA) matrix provides theConcepts-Concepts model (CC). In this case, clustering also produces a meaningful result: the connections between the concepts that share the same actors canbe seen. In a similar fashion, we obtain the matrices Concepts-Concepts (CC)and Instances-Instances (II) from the bipartite (CI) model, and Actors-Actors(AA) and Instances-Instances (II) from the bipartite Concepts-Instances model.As it can be seen, (AA), (CC) and (II) matrices have been obtained twice. Thedi&#64256;erence is that (AA) in one case re&#64258;ects the connection between the actors onthe concept layer, and in the other case - on the instance layer, and similarly forthe matrices (CC) and (II).3ExperimentsA corpus of 250 articles on education has been compiled for testing. We considerthis amount enough for a pilot study, because we can easily check the performance of clustering and opinion measurement algorithms. An excerpt from anarticle on education (translated) is given in Fig. 1. In this text we can &#64257;nd theelements belonging to the three layers: S. Rukshin, A. Kiryanov, D. Medvedyev(Actors); Education (Concepts); gifted children, lyceums (Instances).We consider two main operations on the obtained models: clustering (unipartite model) and opinion polarity analysis (tripartite and bipartite models).3.1Model ConstructionDocument models are built based on a corpus model, which includes 3 keywordlists forming the actor, concept and instance dimensions. The corpus is createdA Modified Tripartite Model for Document Representation327Fig. 1. A sample document (educational domain)using keyword-based queries, where the keywords cannot be randomly selectedand should represent a description of a certain topic. The three-layer model construction includes two steps: (i) identify the descriptors (keywords and keyphasesdenoting actors, concepts and instances within the given corpus) for each layer;(ii) parametrize texts in the three dimensions.Identification of DescriptorsThe extraction of actors and instances is a named entity recognition (NER)task. As a solution, we extract single terms on the basis of their speci&#64257;city criterium using LexisTerm-I [2]. Term frequencies can be counted either in &#8220;Corpus&#8221; mode for the whole corpus or in &#8220;Document&#8221; mode for each particulardocument. In this implementation, LexisTerm-I proposes some candidates forthe construction of actor, instance and concept lists, and an expert does themanual correction of the obtained list. At a later stage, we plan to make theprocedure totally automatic using approaches described in [8&#8211;10].Actors List. The frequency of actors in the domain-speci&#64257;c documents isassumed to be higher than in the general lexis, therefore, they are detectedin the &#8220;Document&#8221; mode. Our education-related corpus contains n = 50 actornames, where there are 30 person names and 20 organization names. Each listelement includes 1&#8211;5 tokens, which allows to record full names with titles (e.g.,Dr. Dmitry Livanov), and full organization names (e.g., Ministry of Science andEducation).Concepts List. The terms have been extracted by LexisTerm-I for K = 10 inthe &#8220;Corpus&#8221; mode. Each concept in the resulting list includes one or severalwords. The sample main concepts are as follows: education accessibility, youngtalents, Uni&#64257;ed State Exam, etc.. Within the &#8220;Education&#8221; domain we distinguishM = 10 subtopics, for which keyword lists are manually created. The numberof descriptors cannot be higher than 20, which, from our experience, is enough.The number of tokens per concept together with descriptors varies from 1 to 5.Instances List. The instance list is constructed using the results of LexisTermI text processing in the &#8220;Document&#8221; mode. Each instance is represented by 3components: (i) an object or event; (ii) object/event location; (iii) object/eventdate. The sample instances are the Law of Education, the decree on the creationof a lyceum network, Moscow school merging, etc. There is also a &#64257;xed list oflocations: Parliament, President&#8217;s Council, Moscow Government, etc. The date328M. Alexandrov et al.includes the related month and year. The resulting list includes thus the followingcomponents: [object1 , object2 , ...objectn ], [location1 , location2 , ...locationn ], and(month, year). For our corpus, the list of objects and events contains P = 20elements, the list of locations - Q = 15 elements. Each element&#8217;s length is of 1&#8211;5tokens.Document ParametrizationDocument parametrization is the representation of a document in the threedimensions of actors, concepts, and instances on the basis of the corpus modelperformed with the ParamDoc-3D program. Operations on two dimensions areperformed in ParamDoc-2D, and on one dimension - in ParamDoc-1D [1]. Thebase tripartite model is parametrized as follows.Actor Dimension. All actor mentions from the N -actor list of the corpus modelin a document are collected. The actor mention is selected if it corresponds tothe expert-established settings. For unigrams, a complete match is obviouslyrequired. In case of 2&#8211;5 token keywords, a complete or partial match (2-3 tokens)can be set.Concept Dimension. The weight of each topic in a document is measured usinga vocabulary of the corresponding descriptors. A topic with the highest weight, ortopics with the weights exceeding certain threshold are selected. The calculationuses the following method [5]: (a) measure the text coverage by the vocabulary(total density of the descriptors), (b) measure the vocabulary coverage by thetext (percentage of vocabulary entries&#8217; mentions), (c) measure the total coverage.Both coverages can take on a value [0.0, 5.1] using a non-linear scale. The totalvalue can range from 0 to 2. By establishing a threshold, we can sort out a setof topics present in a document.Instance Dimension. Instance extraction is done in 3 steps: (1) search for anevent or object from the list of P -instances of the corpus model, (2) search forlocation triggers from the list of Q-locations of the corpus model, (3) search forthe mentions of month and year in the document body. Objects, events, andlocations are extracted similarly to actors: total and partial matches of the 1&#8211;5token sets are considered. As for the date, texts often contain several mentions,in which case at most 5 of them are extracted.3.2Opinion MiningAt the end of 2013 the Russian Federation authorities approved the Law of Education. This event was preceded by a long evaluation of the contents of the Lawby the educational community, the Parliament and the Government. It was atough debate, due to the con&#64258;ict between the market-driven and the traditionalapproach to state education &#64257;nancing in the country. We have performed theopinion mining using GMDH [1,3] for the pairs from actor and instance dimensions (Table 2).It can be seen that the negative attitude was expressed mostly towards apublic organization (the Civic Chamber), and not towards the governmentalA Modified Tripartite Model for Document Representation329Table 2. Distribution of opinions on the Law of educationActorInstanceNegPos.The Civic ChamberLaw of Education 72 % 18 %Ministry of Education Law of Education 55 % 45 %Table 3. Contents of the main actor and instance clustersNo. Actor cluster contentsInstance cluster contents1abramov, rukshin, kovaldzhi, kuzminov, higher school of Strategy, law, standard, lyceumseconomics, international monetary fund, world bank,russian ministry of education, civic chamber of therussian federation2malinetsky, efimov, moscow institute of physics andtechnology, institute of international programsKorea, China, Singapore3......structures (Ministry of Education). It can be easily explained, because there aremany followers of unpopular reforms in the mentioned public organization.3.3ClusteringClustering experiments have been carried out using the MajorClust method [7,14] to group actors and instances in the concept dimension. Earlier, MajorClustproved its e&#64259;ciency in short texts processing [4,12]. The results are shown inthe Table 3.The &#64257;rst Actor cluster includes person and organization names related tothe topics &#8220;secondary school&#8221;, &#8220;gifted children&#8221;, &#8220;reforms &#64257;nancing&#8221;. The second cluster contains person and organization names, related to the topics &#8220;highschool&#8221;, &#8220;science&#8221;, &#8220;modeling&#8221;. The &#64257;rst Instance cluster spans instances, relatedto lawmaking, which are in turn related to the topics &#8220;secondary school&#8221; and&#8220;gifted children&#8221;. The second cluster includes all the countries, where the authorities have been actively supporting young talents in the recent years (key phrases:&#8220;gifted children&#8221;, &#8220;innovations&#8221;, &#8220;Asia&#8221;).4Conclusion and Future WorkThe present paper describes a document representation model, based on thetripartite model of ontologies by Peter Mika (Yahoo! Research), which can beuseful for the solution of Internet Sociology tasks. The results of a pilot experiment are presented. Information on the deployment of the developed tools isprovided. As the future work, we plan to do the following:&#8211; Investigate the behaviour of the proposed model in more detail. To this end:&#8226; Evaluate the proposed model on a larger corpus;&#8226; Perform clustering in the actor and instance dimensions;&#8211; Develop the necessary tools that will allow to:&#8226; Perform document parametrization automatically;&#8226; Visualize the results so that they can be easily interpreted.330M. Alexandrov et al.</corps><conclusion> and Future WorkThe present paper describes a document representation model, based on thetripartite model of ontologies by Peter Mika (Yahoo! Research), which can beuseful for the solution of Internet Sociology tasks. The results of a pilot experiment are presented. Information on the deployment of the developed tools isprovided. As the future work, we plan to do the following:&#8211; Investigate the behaviour of the proposed model in more detail. To this end:&#8226; Evaluate the proposed model on a larger corpus;&#8226; Perform clustering in the actor and instance dimensions;&#8211; Develop the necessary tools that will allow to:&#8226; Perform document parametrization automatically;&#8226; Visualize the results so that they can be easily interpreted.330M. Alexandrov et al.</conclusion><discussion> </discussion><biblio>1. Alexandrov, M.: Development of general methodology for analysis of public opinion of Internet-community and its application to given topics (authority, economy, corruption, etc.) on the basis of Data/Text Mining tools. Report on State project 84, RPANEPA [rus] (2013)
 2. Alexandrov, M., Beresneva, D., Makarov, A.: Dynamic vocabularies as a tool for studying social processes. In: Proceedings of the 6th International Conference on Intelligent Information and Engineering Systems, ITHEA Publishing, vol. 27, pp. 88&#8211;92 (2014)
 3. Alexandrov, M., Danilova, V., Koshulko, A., Tejada, J.: Models for opinion classification of blogs taken from Peruvian Facebook. In: Proceedings of the 4th International Conference on Inductive Modeling (ICIM-2013), Kyiv, Ukraine Publishing House ITRC-NASU (Ukraine) &amp; Czech Technical University pp. 241&#8211;246 (2013)
 4. Alexandrov, M., Gelbukh, A., Rosso, P.: An approach to clustering abstracts. In: Montoyo, A., Mun&#771;oz, R., Me&#769;tais, E. (eds.) NLDB 2005. LNCS, vol. 3513, pp. 275&#8211;285. Springer, Heidelberg (2005)
 5. Alexandrov, M., Gelbukh, A., Makagonov, P.: Evaluation of thematic structure of multidisciplinary documents and document flows. In: Proceedings of the 11th International DEXA Workshop (Database and Expert System Applications), pp. 125&#8211;129 (2000)
 6. Baeza-Yates, R., Ribero-Neto, B.: Modern Information Retrieval. Addison Wesley, Boston (1999)
 7. Bishop, C.: Pattern Recognition and Machine Learning. Springer, Berkeley (2006)
 8. Danilova, V., Alexandrov, M., Blanco, X.: A survey of multilingual event extraction from text. In: Me&#769;tais, E., Roche, M., Teisseire, M. (eds.) NLDB 2014. LNCS, vol. 8455, pp. 85&#8211;88. Springer, Heidelberg (2014)
 9. Danilova V., Popova S.: Socio-political event extraction using a rule-based approach. In: Meersman, R., Panetto, H., Mishra, A., Valencia-Garcia, R., Soares, A.L., Ciuciu, I., Ferri, F., Weichhart, G., Moser, T., Bezzi, M., Chan, H. (eds.) Proceedings of the 13th International Conference on Ontologies, DataBases and Applications of Semantics (ODBASE&#8217;2014), vol 8842, pp. 537&#8211;546, Springer (2014)
 10. Gelbukh, A., Sidorov, G., Guzman-Arenas, A.: Use of a weighted topic hierarchy for document classification. In: Matous&#780;ek, V., et al. (eds.) TSD 1999. LNCS (LNAI), vol. 1692, pp. 133&#8211;138. Springer, Heidelberg (1999)
 11. Manning, C., Raghavan, P., Schutze, H.: Introduction to Information Retrieval. Cambridge University Press, Cambridge (2008)
 12. Eissen, S.M., Stein, B.: Analysis of clustering algorithms for web-based search. In: Karagiannis, D., Reimer, U. (eds.) PAKM 2002. LNCS (LNAI), vol. 2569, pp. 168&#8211;178. Springer, Heidelberg (2002)
 13. Mika, P.: Ontologies are us: a unified model of social networks and semantics. J. Web Semant. Sci. Serv. Agents World Wide Web 5(1), 5&#8211;15 (2007)
 14. Stein, B., Niggemann, O.: On the nature of structure and its identification. In: Widmayer, P., Neyer, G., Eidenbenz, S. (eds.) WG 1999. LNCS, vol. 1665, p. 122. Springer, Heidelberg (1999)
  </biblio></article>