<article><preamble>Gonzalez 2018 Automated Sentence Boundary Detection in Modern StandardArabic Transcripts using Deep Neural Networks</preamble><titre>Available</titre><auteur>Available online
online at
at www.sciencedirect.com
www.sciencedirect.com

Available online at www.sciencedirect.com

ScienceDirect

Available online at www.sciencedirect.com
Procedia Computer Science 00 (2018) 000&#8211;000
Procedia
Computer
Science
(2018)
000&#8211;000
Procedia
Computer
Science
14200
(2018)
339&#8211;346

www.elsevier.com/locate/procedia
www.elsevier.com/locate/procedia

Procedia Computer
Science 00
(2018) 000&#8211;000
The
on
Computational
Linguistics
(ACLing
The 4th
4th International
International Conference
Conference
on Arabic
Arabic
Computational
Linguistics
(ACLing 2018),
2018),
www.elsevier.com/locate/procedia
November
17-19
2018,
Dubai,
United
Arab
Emirates
November 17-19 2018, Dubai, United Arab Emirates

Automated
Sentence
Boundary
Detection
Modern
Standard
Automated
Sentence
Boundary
Detection in
in
Modern
Standard
The 4th International
Conference
on Arabic Computational
Linguistics
(ACLing
2018),
November
17-19
2018,
Dubai,
United
Arab
Emirates
Arabic
Arabic Transcripts
Transcripts using
using Deep
Deep Neural
Neural Networks
Networks
a,&#8727; Detection in Modern
aa
b
Automated
Sentence
Boundary
Standard
b,
Carlos-Emiliano
Pontes
,, Fatiha
Sadat
Carlos-Emiliano Gonza&#769;lez-Gallardo
Gonza&#769;lez-Gallardoa,&#8727;,, Elvys
Elvys Linhares
Linhares
Pontes
Fatiha
Sadat
,
a,b,c
a,b,c
Juan-Manuel
Torres-Moreno
Arabic Transcripts
using
Deep Neural Networks
Juan-Manuel
Torres-Moreno
a LIA - Universite&#769; d&#8217;Avignon et des Pays de Vaucluse, 339 chemin des Meinajaries, 84140, Avignon, France
a LIA - Universite&#769; d&#8217;Avignon et des Pays de Vaucluse, 339 chemin des Meinajaries, 84140, Avignon, France
a,&#8727;
a
b Universite&#769; du Que&#769;bec a Montre&#769;al, C.P. 8888, succ.
Montre&#769;al (Que&#769;bec) H3C 3P8 Canada
b Universite&#769; du Que&#769;bec a Montre&#769;al, C.P. 8888, succ. Centre-ville,
Centre-ville, Montre&#769;al (Que&#769;bec) H3C 3P8 Canada

Carlos-Emiliano Gonza&#769;lez-Gallardo , Elvys Linhares Pontes , Fatiha Sadatb ,
c GIGL, E&#769;cole Polytechnique de Montre&#769;al, C.P. 6079, succ. Centre-ville, Montre&#769;al
H3C 3A7 Canada
c GIGL, E&#769;cole Polytechnique de Montre&#769;al, C.P. 6079, succ. Centre-ville, Montre&#769;al
(Que&#769;bec) H3C 3A7 Canada
Juan-Manuel Torres-Morenoa,b,c (Que&#769;bec)
a LIA

</auteur><abstract>Abstract- Universite&#769; d&#8217;Avignon et des Pays de Vaucluse, 339 chemin des Meinajaries, 84140, Avignon, Francedu Que&#769;bec a Montre&#769;al, C.P. 8888, succ. Centre-ville, Montre&#769;al (Que&#769;bec) H3C 3P8 Canadac GIGL, E&#769;cole Polytechnique de Montre&#769;al, C.P. 6079, succ. Centre-ville, Montre&#769;al (Que&#769;bec) H3C 3A7 Canadab Universite&#769;TheThe increasedincreased volumesvolumes ofof ArabicArabic sourcessources ofof datadata availableavailable onon thethe WebWeb hashas boostedboosted thethe developmentdevelopment ofof NaturalNatural LanguageLanguage ProcessingProcessing(NLP)(NLP) toolstools overover differentdifferent taskstasks andand applications.applications. However,However, toto taketake advantageadvantage fromfrom aa vastvast amountamount ofof thesethese applications,applications, aa priorpriorsegmentationAbstractsegmentation tasktask callcall SentenceSentence BoundaryBoundary DetectionDetection (SBD)(SBD) isis needed.needed. InIn thisthis paperpaper wewe focusfocus onon SBDSBD overover ModernModern StandardStandard ArabicArabic(MSA)(MSA) byby comparingcomparing twotwo differentdifferent approachesapproaches basedbased onon DeepDeep NeuralNeural NetworksNetworks (DNN)(DNN) usingusing out-of-domainout-of-domain andand in-domainin-domain trainingtrainingTheincreasedvolumes featuresof Arabic sources of dataavailable on the Web hasboosted the developmentof Natural LanguageProcessingdatadata withwith onlyonly lexicallexical features (represented(represented asas charactercharacter embedding)embedding) whilewhile conductingconducting twotwo scenariosscenarios basedbased onon aa ConvolutionalConvolutional(NLP)tools overanddifferent tasks Neuraland applications.withHowever, tomechanismtake advantage from a vastamount ofatheseapplications, a priorNeuralNeural NetworkNetwork and aa RecurrentRecurrent Neural NetworkNetwork with attentionattention mechanism architectures.architectures. WhileWhile tuningtuning a bigbig out-of-domainout-of-domain datasetdatasetsegmentationtaskcall SentenceBoundaryDetection(SBD) is needed.In thispaperwe focuson SBDoverModernStandardArabicwithasmallerin-domaindataset,improvestheperformanceingeneral.OurevaluationswerebasedonIWSLTwith a smaller in-domain dataset, improves the performance in general. Our evaluations were based on IWSLT 20172017 TEDTED talkstalks(MSA)by comparingtwodifferent approachesbaseddependingon Deep NeuralNetworks(DNN)MSAusingcarriesout-of-domainand in-domaingiventrainingtranscriptsandshowedsimilaritiesanddifferencesoftheSBDmethod.certaincomplicationstranscripts and showed similarities and differences depending of the SBD method. MSA carries certain complications given itsitsdatawith only lexicalfeatures (representedas characterembedding)while conductingtwo scenariosbased on thea Convolutionalrichrich andand complexcomplex morphology.morphology. However,However, usingusing onlyonly lexicallexical featuresfeatures forfor ArabicArabic SBDSBD isis anan acceptableacceptable optionoption whenwhen the sourcesource audioaudioNeuralNetworkand a RecurrentNeural Networkwith attention mechanismarchitectures.While tuning a big out-of-domain datasetsignalsignal isis notnot availableavailable andand aa certaincertain levellevel ofof languagelanguage independenceindependence needsneeds toto bebe reached.reached.with a smaller in-domain dataset, improves the performance in general. Our evaluations were based on IWSLT 2017 TED talksSentenceBoundaryDetection;Transcription;ModernNeuralNetworks</abstract><introduction>Introduction
Arabic
Arabic language
language is
is known
known to
to be
be challenging
challenging given
given its
its complex
complex linguistic
linguistic structure
structure [3]
[3] and
and dialect
dialect variations
variations [14].
[14].
However,
the
development
of
Arabic
Natural
Language
Processing
(NLP)
tools
has
increased
these
last
However,
the development of Arabic Natural Language Processing (NLP) tools has increased these last years,
years, creating
creating
1. Introduction
aa large
large set
set of
of state-of-the-art
state-of-the-art applications
applications including
including POS
POS taggers,
taggers, syntactic
syntactic parsers,
parsers, information
information retrieval,
retrieval, machine
machine
translation,
automatic
speech
recognition
and
synthesis
systems
[9,
17].
Some
NLP
libraries
and
like
translation,
automatic
speech
and given
synthesis
systems linguistic
[9, 17]. Some
NLP [3]
libraries
and tools
tools
like Python
Python
Arabic
language
is known
to recognition
be challenging
its complex
structure
and dialect
variations
[14].
However, the development of Arabic Natural Language Processing (NLP) tools has increased these last years, creating
a &#8727;large
set of state-of-the-art
applications
author. Tel.: +33 04
90 84 35 68. including POS taggers, syntactic parsers, information retrieval, machine
&#8727; Corresponding
Corresponding author. Tel.: +33 04 90 84 35 68.
translation,
automatic
speech
recognition
and synthesis systems [9, 17]. Some NLP libraries and tools like Python
E-mail address: carlos-emiliano.gonzalez-gallardo@alumni.univ-avignon.fr
E-mail address: carlos-emiliano.gonzalez-gallardo@alumni.univ-avignon.fr

c 2018 The Authors. Published by Elsevier B.V.
1877-0509 
c 2018 The Authors. Published by Elsevier B.V.
1877-0509 
&#8727; is an open
1877-0509
&#169; 2018
Thearticle
Authors.
Published
by35Elsevier
B.V.
This
access
under
the
CC84
BY-NC-ND
license (http://creativecommons.org/licenses/by-nc-nd/3.0/)
author.
Tel.:
+33
04 90
68.
ThisCorresponding
is an open access
article
under
the
CC BY-NC-ND
license (http://creativecommons.org/licenses/by-nc-nd/3.0/)
This
is
an
open
access
article under
CC BY-NC-ND
(http://creativecommons.org/licenses/by-nc-nd/3.0/)
Peer-review
under
responsibility
of thethe
scientific
committeelicense
of the 4th
International Conference on Arabic Computational Linguistics.
E-mail
address:
carlos-emiliano.gonzalez-gallardo@alumni.univ-avignon.fr
Peer-review
under
responsibility
of
the
scientific
committee
of theof4th
International
Conference
on ArabiconComputational
Linguistics.Linguistics.
Peer-review under responsibility of the scientific committee
the
4th International
Conference
Arabic Computational
10.1016/j.procs.2018.10.485
c 2018 The Authors. Published by Elsevier B.V.
1877-0509 
This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/3.0/)
Peer-review under responsibility of the scientific committee of the 4th International Conference on Arabic Computational Linguistics.

340	
2

Carlos-Emiliano Gonz&#225;lez-Gallardo et al. / Procedia Computer Science 14</introduction><corps>IntroductionArabicArabic languagelanguage isis knownknown toto bebe challengingchallenging givengiven itsits complexcomplex linguisticlinguistic structurestructure [3][3] andand dialectdialect variationsvariations [14].[14].However,thedevelopmentofArabicNaturalLanguageProcessing(NLP)toolshasincreasedtheselastHowever,the development of Arabic Natural Language Processing (NLP) tools has increased these last years,years, creatingcreating1. Introductionaa largelarge setset ofof state-of-the-artstate-of-the-art applicationsapplications includingincluding POSPOS taggers,taggers, syntacticsyntactic parsers,parsers, informationinformation retrieval,retrieval, machinemachinetranslation,automaticspeechrecognitionandsynthesissystems[9,17].SomeNLPlibrariesandliketranslation,automaticspeechand givensynthesissystems linguistic[9, 17]. SomeNLP [3]librariesand toolstoolslike PythonPythonArabiclanguageis knownto recognitionbe challengingits complexstructureand dialectvariations[14].However, the development of Arabic Natural Language Processing (NLP) tools has increased these last years, creatinga &#8727;largeset of state-of-the-artapplicationsauthor. Tel.: +33 0490 84 35 68. including POS taggers, syntactic parsers, information retrieval, machine&#8727; CorrespondingCorresponding author. Tel.: +33 04 90 84 35 68.translation,automaticspeechrecognitionand synthesis systems [9, 17]. Some NLP libraries and tools like PythonE-mail address: carlos-emiliano.gonzalez-gallardo@alumni.univ-avignon.frE-mail address: carlos-emiliano.gonzalez-gallardo@alumni.univ-avignon.frc 2018 The Authors. Published by Elsevier B.V.1877-0509 c 2018 The Authors. Published by Elsevier B.V.1877-0509 &#8727; is an open1877-0509&#169; 2018ThearticleAuthors.Publishedby35ElsevierB.V.ThisaccessundertheCC84BY-NC-NDlicense (http://creativecommons.org/licenses/by-nc-nd/3.0/)author.Tel.:+3304 9068.ThisCorrespondingis an open accessarticleundertheCC BY-NC-NDlicense (http://creativecommons.org/licenses/by-nc-nd/3.0/)Thisisanopenaccessarticle underCC BY-NC-ND(http://creativecommons.org/licenses/by-nc-nd/3.0/)Peer-reviewunderresponsibilityof thethescientificcommitteelicenseof the 4thInternational Conference on Arabic Computational Linguistics.E-mailaddress:carlos-emiliano.gonzalez-gallardo@alumni.univ-avignon.frPeer-reviewunderresponsibilityofthescientificcommitteeof theof4thInternationalConferenceon ArabiconComputationalLinguistics.Linguistics.Peer-review under responsibility of the scientific committeethe4th InternationalConferenceArabic Computational10.1016/j.procs.2018.10.485c 2018 The Authors. Published by Elsevier B.V.1877-0509 This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/3.0/)Peer-review under responsibility of the scientific committee of the 4th International Conference on Arabic Computational Linguistics.340	2Carlos-Emiliano Gonz&#225;lez-Gallardo et al. / Procedia Computer Science 142 (2018) 339&#8211;346C.E. Gonza&#769;lez-Gallardo et al. / Procedia Computer Science 00 (2018) 000&#8211;000NLTK1 , OpenNLP2 [5], UIMA3 [10], LIMA4 and NooJ5 [26], which were originally created for non Arabic texts nowinclude Arabic extensions. By contrast, other libraries have been developed exclusively for Arabic.Althobaiti et al. developed AraNLP [2], which is focused on Arabic preprocessing. This library contains some toolscovering tokenization, stemming, POS tagging, sentence detection, word segmentation, normalization and punctuation/diacritic deletion.MADAMIRA6 , developed by Pasha et al., is an toolkit which combines two previous Arabic NLP systems:MADA[13] and AMIRA[7]. It provides the following NLP tools for Modern Standard Arabic (MSA) and the Egyptiandialect: lemmatization, diacritization, glossing, POS tagging, morphological analysis, morphological disambiguation,stemming, tokenization, base phrase chunking, name entity recognition and word-level disambiguation [23].The Software Architecture For Arabic language pRocessing (SAFAR) [27] is a framework developed by Soutehet al. that aims to gather developed Arabic NLP tools within a single homogeneous architecture and create newones if necessary. Implemented tools within SAFAR include morphological analyzers, stemmers, syntactic parsers,normalizers, tokenizers, sentence splitters, transliteration tools and question answering applications.Works have also been made regarding unstructured and noisy Arabic texts, found in social media datasets likemicroblogs and tweets. Added to the common difficulties of working with structured Arabic texts, Arabic tweets carryother problems like high degree of ambiguity, spelling mistakes, etc. Mallek et al. [20] implemented a phrase-basedstatistical machine translation system from MSA tweets into English. They conclude that a preprocessing step for thiskind of noisy texts is very useful to improve the translation results. El-Masri et al. [8] presented a sentiment analysistool over Arabic tweets using a Naive Bayes learning approach. Their model detects the polarity of a group of tweetclassifying it in four possible classes: positive, negative, both and neutral.Access to Internet multimedia platforms nowadays available like Youtube7 , TED8 and Dailymotion9 opens a newuniverse for Arabic NLP tools. Automatic Speech Recognition (ASR) systems can be used to transcribe multimediacontent ASR aims to transform spoken data into a written representation, thus enabling natural human-machine interaction with further NLP tasks [31]. Performance of ASR systems for MSA has improve in the last years given theamount of data available for training and testing this systems. Tomashenko et al. [28] trained a Deep Neural Network(DNN) with Gaussian Mixture Models derived features and time-delay neural networks for acoustic models over 1128hours of MSA broadcast speech and 110 million words, reporting a WER of 23%. Menacer et al. [21] developed anASR system for MSA based on the Kaldi toolkit10 [25], where recognition is achieved using a DNN Hidden Markovmodel over 63 hours of spoken transcribed data and 1000 million words from the Arabic Gigaword Corpus. Theyreported a result of 14.42% in terms of WER.Despite the good performance of modern ASR systems, transcripts do not carry syntactic information as sentenceboundaries, which is a major problem for further NLP tasks like POS tagging, automatic text summarization [29],machine translation and sentiment analysis among others. In this paper we address the Sentence Boundary Detection(SBD) task over MSA transcripts to automatically predict or restore the boundaries over transcripts.The rest of this article is organized as follows. In Section 2 we present an overview of related work concerning SBD.The experimental setup is introduced in Section 3. Experiments and results are addressed in Section 4. In Section 5Discussion over the methods and difficulties are presented. Finally, Section 6 concludes the paper.12345678910https://www.nltk.org/https://opennlp.apache.org/https://uima.apache.org/https://github.com/aymara/lima/wikihttp://www.nooj-association.org/https://camel.abudhabi.nyu.edu/madamira/https://www.youtube.com/https://www.ted.com/https://www.dailymotion.com/frhttp://kaldi-asr.org/	Carlos-Emiliano Gonz&#225;lez-Gallardo et al. / Procedia Computer Science 142 (2018) 339&#8211;346C.E. Gonza&#769;lez-Gallardo et al. / Procedia Computer Science 00 (2018) 000&#8211;00034132. Sentence Boundary Detection for MSASentence Boundary Detection (SBD) is of vital importance given that in general, ASR systems focus on obtaining thecorrect sequence of transcribed words with almost no concern of the overall structure of the document, thus lackingof syntactic information [12].A big complication of segmenting a transcript is the flurry definition of sentence in spoken language. In standardconversations or in simpler scenarios like a monologue, ideas are organized very differently compared to writtenlanguage. Added to this, Arabic carries other difficulties like word ambiguity, structural ambiguity, lack of punctuationmarks, use of connective words and agglutination [15].To our knowledge no much work has been developed over Arabic SBD. The Arabic Texts Segmentation Systemor STAr (by its acronym in French), created by Belguith et al. [15] is a text segmentation system for Arabic basedon a set of rules created from the contextual analysis of punctuation marks and a list of particles which play the roleof sentence boundaries. Segmentation consists on the disambiguation of sentence boundaries and paragraphs. Eventhough they did not report any experiment with transcripts, while it is possible to apply the method over this type ofdata.Zribi et al. [32] presented three methods for the detection of sentence boundaries in transcribed Tunisian Arabicusing lexical and prosodic features. The first method is composed of two sets of handmade rules: 1) based on oralspecific lexical items and prosodic features and 2) based on connectors, personal and relative pronouns, verbs, etc.The second method corresponds to a statistical method based on a decision tree algorithm. It classifies a word intofour different classes: 1) first word of a sentence, 2) word within a sentence, 3) last word of a sentence and 4) oneword sentence. The third method combines the previous two in an hybrid framework.3. Methodology3.1. DatasetsOne of the objectives of the current research is to analyze the impact of cross-domain datasets during the evaluation phase of SBD. The first dataset (TED) corresponds to the Multilingual Task 2017 proposed by The InternationalWorkshop on Spoken Language Translation (IWSLT)11 . It consists of 122 TED talks12 manually transcribed containing 168,354 words. The second dataset (GW) is the Arabic Gigaword13 , which gathers a series of different Arabicnews wires containing around 938M words (after XML extraction). We used a sample of 70,261,169 words whichcorresponds to the Asharq Al-Awsat (aaw arb) news wire.As for the preprocessing, we applied a normalization and tokenization process over both datasets. During thenormalization phase, all punctuation marks (  ?  !  ,  . : ;) were mapped to a common boundary symbol, whichcorresponds to the &#8221;BOUNDARY&#8221; class. Based on the experiments performed by Alotaiby et al. [1], where they observed that a big lexicon could be reduced about 24.54%, we used the MADAMIRA toolkit to perform a tokenizationover both datasets to reduce the dimensionality. The following proclitics and enclitics were separated, generating twoor more tokens depending of the amount of clitics within the word:                	                  The final size of the datasets after normalization and tokenization as well as the training, validation and testingdistribution can be observed in Table 1. We opted to omit the validation set for TED given its reduced size.111213http://workshop2017.iwslt.org/https://www.ted.com/talks?language=enhttps://catalog.ldc.upenn.edu/LDC2011T11Carlos-Emiliano Gonz&#225;lez-Gallardo et al. / Procedia Computer Science 142 (2018) 339&#8211;346C.E. Gonza&#769;lez-Gallardo et al. / Procedia Computer Science 00 (2018) 000&#8211;000342	4It is important to remark the class distribution disparity. Given the nature of the dataset, where sentence boundaries are much less frequent that nonsentence boundaries, the &#8221;BOUNDARY&#8221; class oscillates between 6.185% and9.981% (Table 2). Liu et al. developed a wide study [19] addressing this disparity behavior with techniques like downsampling, oversampling and replication in a Hidden Markov Model framework. They concluded that depending onthe evaluation metric and posterior processing, resampling may or not be useful. Table 1 and 2 show some statisticson the dataset as well as the classes distributions over these datasets.Table 1. Size and distribution of datasets.DatasettrainvalidtestTotalGWTED73,608,328183,31421,030,957&#8212;10,515,47750,881105,154,7621942,378Table 2. Class distribution in percentage (%) over datasets.ClasstrainGWvalidtesttrainTEDtestBOUNDARYNO BOUNDARY6.18593.8156.51993.4816.66393.3379.98190.0199.69990.3013.2. Character embeddingsWord representation is an important topic to consider specially for morphology rich languages like Arabic. Commonembedding strategies like Word2vec [22] or Glove [24] do not consider the internal structure of words, which isa limitation for morphology rich languages. FastText14 , proposed by Bojanowski et al. [6], is a word embeddingrepresentation where a vector is associated to each n-gram character; therefore, words are represented as the sum oftheir character vectors.We opted for FastText vectors to represent our datasets and conduct our experiments given its advantages concerning morphology rich languages. We performed a 300 dimension vector induction with the complete GW datasetobtaining 102,248 vectors.3.3. The Proposed MethodsWe are interested in comparing addressed Arabic SBD with two different Neural Network approaches, CNN andRNN.3.3.1. CNN (SBDConv )For this method we took into consideration the Convolutional Neural Network (CNN) models proposed by Gonza&#769;lezGallardo et al. [11] for French SBD. CNN are a type of DNN in which certain hidden layers behave like filters thatshare their parameters across space. At the last part of the CNN, a set of fully connected layers choose within a set ofpossible outputs the most probable one. The input layer of a CNN is represented by a m &#215; n matrix where each cell ci jmay correspond to an image&#8217;s pixel in image processing. For our purpose this matrix represents the relation betweena window of m words and their corresponding n dimensional FastText vectors.The hidden layers inside both CNNs consist of an arrange of convolutional, pooling and fully connected layersblocks. We consider two convolutional layers, with valid padding and stride value of one. The first layer has a 3-shape14https://fasttext.cc/	Carlos-Emiliano Gonz&#225;lez-Gallardo et al. / Procedia Computer Science 142 (2018) 339&#8211;346C.E. Gonza&#769;lez-Gallardo et al. / Procedia Computer Science 00 (2018) 000&#8211;0003435kernel and 32 output filters while the second has a 2-shape kernel and 64 output filters. To downsample and centralizethe attention of the CNN in the middle word of the window, a max pooling layer with 2x3-shape kernel and strideof 1x3 is implemented. The final part of the CNN is formed by 3 fully connected layers with 2048, 4096 and 2048neurons each and a dropout layer attached to the last layer. RELU activation functions are used to remove linearity ofall convolutional, max pooling and fully connected layers.3.3.2. LSTM (SBDLS T M )Inspired by [18, 30], our second model follows a sequence-to-sequence paradigm using the attention mechanism toverify which words of a sentence c represent a sentence boundary (Figure 1). The words in a sentence c are representedby their FastText embedding. Then, a first LSTM encodes this sentence [16] and a second LSTM with attentionmechanism generates the sequence of labels that determine the sentence boundary. The attention mechanism decideswhich input region to focus in order to generate the next output [4]. LSTM with attention mechanism is composed ofinput it , control state ct and memory state mt that are updated at time step t (Equations 2-7).ct = [wet , ct ](1)it = sigm(W1 xt + W2 ht&#8722;1 )(2)it = tanh(W3 xt + W4 ht&#8722;1 )(3)ft = sigm(W5 xt + W6 ht&#8722;1 )(4)ot = sigm(W7 xt + W8 ht&#8722;1 )(5)mt = mt&#8722;1  ft + it  it(6)ht = mt  ot(7)where the operator  denotes element-wise multiplication, wet is the FastText embedding of the word at the time stept, ct is the context vector, the matrices W1 , W2 , ..., W8 and the vector h0 are the parameters of the model, and all thenon-linearities are computed element-wise. The context vector ct at time t is calculated as a sum of all hidden statesof the encoder weight:T&#945;t j &#183; hEj(8)ct =j=1rt j = vT&#945; tanh(W&#945; ht&#8722;1 + U&#945; hEj )&#945;t j = softmax(rt j )(9)(10)the probability &#945;t j represents the importance of each hidden state of the encoder hEj in the prediction of the currentstate ht .4. Experiments and EvaluationsWe conducted two experimental scenarios for SBD over MSA using the neural models described in Section 3.3. Lexical features for both DNN models correspond to the FastText character embeddings described in Section 3.2. Vectorsof OOV words from the embedding model are generated from the word&#8217;s n-grams vectors, eliminating unknownvectors.The performance is measured as a binary classification task, where the &#8221;BOUNDARY&#8221; (BOUND) class corresponds to the words followed by a punctuation mark, while the &#8221;NO BOUNDARY&#8221; (NO BOUND) class correspondsto those words not followed by a punctuation mark. Given the unbalanced nature of the dataset, a global metric likeAccuracy is likely to be biased by the larger class; thus we also compute Precision, Recall and F1 for each class.Carlos-Emiliano Gonz&#225;lez-Gallardo et al. / Procedia Computer Science 142 (2018) 339&#8211;346C.E. Gonza&#769;lez-Gallardo et al. / Procedia Computer Science 00 (2018) 000&#8211;000344	6Fig. 1. The words are represented by the word embedding representations. The attention mechanism improves the decode processing. The outputlayer is composed of by 0 or 1.4.1. Scenario 1With this first scenario (S1 ) we wanted to observe the impact of applying a SBD model trained with a big datasetcollected from written sources over a spoken source dataset. We first conducted training, validation and test on bothSBDConv and SBDLS T M systems with GW train,valid,test for 3 and 7 epochs respectively. Number of epochs were dynamically decided with GW valid before overfitting. Then, we used TEDtest for evaluating the performance of the trainedmodels over an out-of-domain dataset.Results for this scenario are shown in Table 3. The high Accuracy (0.963) of SBDConv over the GigaWord testdataset (SBDConv(GW) ) may give an erroneous idea of the model performance. This behavior repeats over the rest of themodels. The model is really good predicting the NO BOUND class a F1 of 0.980. It is important to note almost 40%drop in Recall between both classes, which reflects model&#8217;s difficulties to retrieve the corresponding instances of theBOUND class. In most values, SBDLS T M(GW) show a similar performance than SBDConv(GW) . The difference concernsthe BOUND class Recall (0.327) is 46.57% smaller.Evaluation of SBDConv over TEDtest (SBDConv(T ED) ) shows a interesting behaviour when compared to SBDConv(GW) .Difference in Precision for both classes, as well as the NO BOUND class in Recall is very small compared to theRecall BOUND class, which falls about 23.04%. Concerning SBDLS T M for the same test dataset (SBDConv(T ED) ), thebiggest drop in performance also corresponds to the Recall BOUND class, where the difference between them is about35.47%.Table 3. S1 results over GW and TED evaluation datasets.ModelAccuracyPrecisionNO BOUNDBOUNDRecallNO BOUNDBOUNDF1NO BOUNDBOUNDSBDConv(GW)SBDLS T M(GW)0.9630.9470.9720.9540.7970.7290.9890.9910.6120.3270.9800.9720.6840.451SBDConv(T ED)SBDLS T M(T ED)0.9340.9140.9450.9210.7520.6730.9830.9890.4710.2110.9640.9540.5790.3214.2. Scenario 2The objective of the second scenario (S2 ) is to measure the effect of adding a small in-domain spoken dataset overthe models trained on S1 . For this scenario we continued training SBDConv and SBDLS T M systems with TEDtrain .TED dataset size is very small for NN training strategies to consider the creation of a validation set. For this reason,GW valid was used during validation phase and epoch control for both systems. The reduced size of TEDtrain lead to a	Carlos-Emiliano Gonz&#225;lez-Gallardo et al. / Procedia Computer Science 142 (2018) 339&#8211;346C.E. Gonza&#769;lez-Gallardo et al. / Procedia Computer Science 00 (2018) 000&#8211;0003457fast overfitting behaviour, SBDConv was trained only for one epoch while X for SBDLS T M . Evaluation was performedover the same dataset of S1 (TEDtest ).Table 4 shows the results for S2 . As in S1 , accuracy values are very high given the class unbalanced. ConcerningSBDConv(T ED) , Precision and Recall for the NO BOUND class is almost the same with just a small difference of 0.005.Continue training SBDConv with TEDtrain seems to have a negative impact over the BOUND class Precision (0.687),which is 8.25% lower than in S1 . However, BOUND class Recall improves 39.1%. SBDLS T M(T ED) show a similarbehavior than SBDConv(T ED) , a slight improvement for the BOUND class Recall is present but a decrease for Pecisionis present.Table 4. S2 results over TED evaluation dataset.ModelSBDConv(T ED)SBDLS T M(T ED)Accuracy0.9380.911PrecisionNO BOUNDBOUND0.9630.9250.6870.597RecallNO BOUND0.9680.981BOUND0.6550.264F1NO BOUND0.9660.952BOUND0.6710.3665. DiscussionResults for S 1 and S 2 show that unbalanced classes distribution seem to impact SBDConv and SBDLS T M in a similardegree even both methods follow very different learning techniques. SBDConv focus its attention on analyzing thewords contained in a fixed-sized window, making the boundary prediction independent of the actual position withinthe transcript. Neverless, this advantage is also a drawback for potentially long sentences given that the method is notable to analyze long contexts.By contrast, the SBDLS T M is characterized by the analysis of a sequence of words to propose the sentence boundaryof this sequence. This approach works best when it analyzes a sequence of words at the beginning of sentences.However, our approach analyzes word sequences that can start in the middle or at the end of sentences, which reducesthe performance of predicting sentence boundaries. In addition, long and complex sentences are a challenge to codeall the information and to generate a correct sentence boundary for this kind of sentences.6. ConclusionIn this paper we have studied the impact of using cross-domain datasets during the evaluation phase of two SentenceBoundary Detection systems over Modern Standard Arabic. The obtained results show that tuning a model that wasoriginally trained with a big out-of-domain dataset with small in-domain dataset, in general, improves its performance.Both methods presented a similar behavior when the spoken language evaluation dataset was used. This may leadto think that spoken MSA maintain the same linguistic structures around SUs than written MSA, but also containssome constructions that written language does not contain.Our method based on LSTM showed to be less effective compared to the one based on CNNs. We think that lettingthe method to learn from more epochs will help to at least equal the performance.As future work we will optimize the training parameters of both methods and increment the number of classes tohave the possibility of different boundary types. Also, a hybrid system using bi-LSTM and CNN that will combinethe advantages of each method, is among our future research directions.AcknowledgementsWe would like to acknowledge the support of CHISTERA-AMIS ANR-15-CHR2-0001 for funding this researchthrough the Access Multilingual Information opinionS (AMIS), (France-Europe) project.346	8Carlos-Emiliano Gonz&#225;lez-Gallardo et al. / Procedia Computer Science 142 (2018) 339&#8211;346C.E. Gonza&#769;lez-Gallardo et al. / Procedia Computer Science 00 (2018) 000&#8211;000</corps><conclusion>In this paper we have studied the impact of using cross-domain datasets during the evaluation phase of two SentenceBoundary Detection systems over Modern Standard Arabic. The obtained results show that tuning a model that wasoriginally trained with a big out-of-domain dataset with small in-domain dataset, in general, improves its performance.Both methods presented a similar behavior when the spoken language evaluation dataset was used. This may leadto think that spoken MSA maintain the same linguistic structures around SUs than written MSA, but also containssome constructions that written language does not contain.Our method based on LSTM showed to be less effective compared to the one based on CNNs. We think that lettingthe method to learn from more epochs will help to at least equal the performance.As future work we will optimize the training parameters of both methods and increment the number of classes tohave the possibility of different boundary types. Also, a hybrid system using bi-LSTM and CNN that will combinethe advantages of each method, is among our future research directions.</conclusion><discussion>We would like to acknowledge the support of CHISTERA-AMIS ANR-15-CHR2-0001 for funding this researchthrough the Access Multilingual Information opinionS (AMIS), (France-Europe) project.346	8Carlos-Emiliano Gonz&#225;lez-Gallardo et al. / Procedia Computer Science 142 (2018) 339&#8211;346C.E. Gonza&#769;lez-Gallardo et al. / Procedia Computer Science 00 (2018) 000&#8211;000</discussion><biblio>[1] Alotaiby, F., Foda, S., Alkharashi, I., 2010. Clitics in arabic language: a statistical study, in: 24th Pacific Asia Conference on Language, Information and Computation  
  [2] Althobaiti, M., Kruschwitz, U., Poesio, M., 2014. Aranlp: A java-based library for the processing of arabic text, in: LREC  
  [3] Attia, M., Somers, H., 2008. Handling Arabic morphological and syntactic ambiguity within the LFG framework with a view to machine translation. volume 279. University of Manchester Manchester  
  [4] Bahdanau, D., Cho, K., Bengio, Y., 2014. Neural machine translation by jointly learning to align and translate. CoRR abs/1409.0473  
  [5] Baldridge, J., 2005. The OpenNLP project. http://opennlp.apache.org/  
  [6] Bojanowski, P., Grave, E., Joulin, A., Mikolov, T., 2016. Enriching word vectors with subword information. preprint arXiv:1607.04606   
  [7] Diab, M., 2009. Second generation amira tools for arabic processing: Fast and robust tokenization, pos tagging, and base phrase chunking, in: 2nd International Conference on Arabic Language Resources and Tools  
  [8] El-Masri, M., Altrabsheh, N., Mansour, H., Ramsay, A., 2017. A web-based tool for arabic sentiment analysis. Procedia Computer Science 117, 38&#8211;45  
  [9] Farghaly, A., Shaalan, K., 2009. Arabic natural language processing: Challenges and solutions. ACM Transactions on Asian Language Information Processing (TALIP) 8, 14  
  [10] Ferrucci, D., Lally, A., 2004. UIMA: An Architectural Approach to Unstructured Information Processing in the Corporate Research Environment. Natural Language Engineering 10, 327&#8211;348. doi:10.1017/S1351324904003523  
  [11] Gonza&#769;lez-Gallardo, C.E., Torres-Moreno, J.M., 2018. Sentence Boundary Detection for French with Subword-Level Information Vectors and Convolutional Neural Networks. preprint arXiv:1802.04559   
  [12] Gotoh, Y., Renals, S., 2000. Sentence boundary detection in broadcast speech transcripts, in: ASR2000-Automatic Speech Recognition: Challenges for the new Millenium ISCA Tutorial and Research Workshop (ITRW)  
  [13] Habash, N., Rambow, O., Roth, R., 2009. Mada+ tokan: A toolkit for arabic tokenization, diacritization, morphological disambiguation, pos tagging, stemming and lemmatization, in: 2nd International Conference on Arabic language resources and tools (MEDAR), Cairo, Egypt, p. 62  
  [14] Habash, N.Y., 2010. Introduction to arabic natural language processing. Synthesis Lectures on Human Language Technologies 3, 1&#8211;187  
  [15] Hadrich, L.B., Baccour, L., Mourad, G., 2005. Star: un syste&#768;me de segmentation de textes arabes base&#769; sur lanalyse contextuelle des signes de ponctuations et de certaines particules, in: TALN&#8217;05  
  [16] Hochreiter, S., Schmidhuber, J., 1997. Long short-term memory. Neural Computation 9, 1735&#8211;1780  
  [17] Jaafar, Y., Bouzoubaa, K., 2018. A survey and comparative study of arabic nlp architectures, in: Intelligent Natural Language Processing: Trends and Applications. Springer, pp. 585&#8211;610  
  [18] Linhares Pontes, E., Huet, S., Torres-Moreno, J.M., Linhares, A.C., 2018. Cross-language text summarization using sentence and multisentence compression, in: Silberztein, M., Atigui, F., Kornyshova, E., Me&#769;tais, E., Meziane, F. (Eds.), Natural Language Processing and Information Systems, Springer International Publishing, Cham. pp. 467&#8211;479  
  [19] Liu, Y., Chawla, N.V., Harper, M.P., Shriberg, E., Stolcke, A., 2006. A study in machine learning from imbalanced data for sentence boundary detection in speech. Computer Speech &amp; Language 20, 468&#8211;494  
  [20] Mallek, F., Le, N.T., Sadat, F., 2018. Automatic machine translation for arabic tweets, in: Intelligent Natural Language Processing: Trends and Applications. Springer, pp. 101&#8211;119  
  [21] Menacer, M.A., Mella, O., Fohr, D., Jouvet, D., Langlois, D., Smaili, K., 2017. An enhanced automatic speech recognition system for arabic, in: Third Arabic Natural Language Processing Workshop, pp. 157&#8211;165  
  [22] Mikolov, T., Chen, K., Corrado, G., Dean, J., 2013. Efficient estimation of word representations in vector space. preprint arXiv:1301.3781   
  [23] Pasha, A., Al-Badrashiny, M., Diab, M.T., El Kholy, A., Eskander, R., Habash, N., Pooleery, M., Rambow, O., Roth, R., 2014. Madamira: A fast, comprehensive tool for morphological analysis and disambiguation of arabic., in: LREC, pp. 1094&#8211;1101  
  [24] Pennington, J., Socher, R., Manning, C., 2014. Glove: Global vectors for word representation, in: Conference on Empirical Methods in Natural Language Processing (EMNLP), pp. 1532&#8211;1543  
  [25] Povey, D., Ghoshal, A., Boulianne, G., Burget, L., Glembek, O., Goel, N., Hannemann, M., Motlicek, P., Qian, Y., Schwarz, P., et al., 2011  
  The Kaldi speech recognition toolkit, in: IEEE 2011 Workshop on Automatic Speech Recognition and Understanding, IEEE Signal Processing Society  
  [26] Silberztein, M., 2005. Nooj: a linguistic annotation system for corpus processing, in: HLT/EMNLP on Interactive Demonstrations, Association for Computational Linguistics. pp. 10&#8211;11  
  [27] Souteh, Y., Bouzoubaa, K., 2011. Safar platform and its morphological layer, in: Eleventh Conference on Language Engineering ESOLEC, pp. 14&#8211;15  
  [28] Tomashenko, N., Vythelingum, K., Rousseau, A., Este&#768;ve, Y., 2016. Lium asr systems for the 2016 multi-genre broadcast arabic challenge, in: Spoken Language Technology Workshop (SLT), 2016, IEEE. pp. 285&#8211;291  
  [29] Torres-Moreno, J.M., 2014. Automatic Text Summarization. Wiley and Sons  
  [30] Tran, N.T., Luong, V.T., Nguyen, N.L.T., Nghiem, M.Q., 2016. Effective attention-based neural architectures for sentence compression with bidirectional long short-term memory, in: Seventh Symposium on Information and Communication Technology, ACM, New York, NY, USA  
  pp. 123&#8211;130. URL: http://doi.acm.org/10.1145/3011077.3011111, doi:10.1145/3011077.3011111  
  [31] Yu, D., Deng, L., 2016. Automatic Speech Recognition. Springer  
  [32] Zribi, I., Kammoun, I., Ellouze, M., Belguith, L., Blache, P., 2016. Sentence boundary detection for transcribed tunisian arabic, in: 13th Conference on Natural Language Processing (KONVENS 2016), pp. 323&#8211;331  
   </biblio></article>